{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1bb429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Total rows: 1597\n",
      "üìã Columns: ['id', 'asins', 'brand', 'categories', 'colors', 'dateAdded', 'dateUpdated', 'dimension', 'ean', 'keys', 'manufacturer', 'manufacturerNumber', 'name', 'prices', 'reviews.date', 'reviews.doRecommend', 'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs', 'reviews.text', 'reviews.title', 'reviews.userCity', 'reviews.userProvince', 'reviews.username', 'sizes', 'upc', 'weight']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>colors</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>dimension</th>\n",
       "      <th>ean</th>\n",
       "      <th>keys</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sizes</th>\n",
       "      <th>upc</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>Paperwhite voyage, no regrets!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cristina M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>One Simply Could Not Ask For More</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ricky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>Great for those that just want an e-reader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tedd Gardiner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>Love / Hate relationship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dougal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>I LOVE IT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miljan David Tanic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id       asins   brand                  categories  \\\n",
       "0  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "1  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "2  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "3  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "4  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "\n",
       "  colors             dateAdded           dateUpdated  \\\n",
       "0    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "1    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "2    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "3    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "4    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "\n",
       "                  dimension  ean                         keys  ...  \\\n",
       "0  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "1  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "2  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "3  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "4  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "\n",
       "  reviews.rating                                 reviews.sourceURLs  \\\n",
       "0            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "1            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "2            4.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "3            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "4            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "2  I am enjoying it so far. Great for reading. Ha...   \n",
       "3  I bought one of the first Paperwhites and have...   \n",
       "4  I have to say upfront - I don't like coroporat...   \n",
       "\n",
       "                                reviews.title reviews.userCity  \\\n",
       "0              Paperwhite voyage, no regrets!              NaN   \n",
       "1           One Simply Could Not Ask For More              NaN   \n",
       "2  Great for those that just want an e-reader              NaN   \n",
       "3                    Love / Hate relationship              NaN   \n",
       "4                                   I LOVE IT              NaN   \n",
       "\n",
       "  reviews.userProvince    reviews.username  sizes upc     weight  \n",
       "0                  NaN          Cristina M    NaN NaN  205 grams  \n",
       "1                  NaN               Ricky    NaN NaN  205 grams  \n",
       "2                  NaN       Tedd Gardiner    NaN NaN  205 grams  \n",
       "3                  NaN              Dougal    NaN NaN  205 grams  \n",
       "4                  NaN  Miljan David Tanic    NaN NaN  205 grams  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"D:/Datasets/7817_1.csv/7817_1.csv\")\n",
    "\n",
    "\n",
    "print(\"üìÑ Total rows:\", len(df))\n",
    "print(\"üìã Columns:\", df.columns.tolist())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53127273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1597 entries, 0 to 1596\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    1597 non-null   object \n",
      " 1   asins                 1597 non-null   object \n",
      " 2   brand                 1597 non-null   object \n",
      " 3   categories            1597 non-null   object \n",
      " 4   colors                774 non-null    object \n",
      " 5   dateAdded             1597 non-null   object \n",
      " 6   dateUpdated           1597 non-null   object \n",
      " 7   dimension             565 non-null    object \n",
      " 8   ean                   898 non-null    float64\n",
      " 9   keys                  1597 non-null   object \n",
      " 10  manufacturer          965 non-null    object \n",
      " 11  manufacturerNumber    902 non-null    object \n",
      " 12  name                  1597 non-null   object \n",
      " 13  prices                1597 non-null   object \n",
      " 14  reviews.date          1217 non-null   object \n",
      " 15  reviews.doRecommend   539 non-null    object \n",
      " 16  reviews.numHelpful    900 non-null    float64\n",
      " 17  reviews.rating        1177 non-null   float64\n",
      " 18  reviews.sourceURLs    1597 non-null   object \n",
      " 19  reviews.text          1597 non-null   object \n",
      " 20  reviews.title         1580 non-null   object \n",
      " 21  reviews.userCity      0 non-null      float64\n",
      " 22  reviews.userProvince  0 non-null      float64\n",
      " 23  reviews.username      1580 non-null   object \n",
      " 24  sizes                 0 non-null      float64\n",
      " 25  upc                   898 non-null    float64\n",
      " 26  weight                686 non-null    object \n",
      "dtypes: float64(7), object(20)\n",
      "memory usage: 337.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d114d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "asins                      0\n",
       "brand                      0\n",
       "categories                 0\n",
       "colors                   823\n",
       "dateAdded                  0\n",
       "dateUpdated                0\n",
       "dimension               1032\n",
       "ean                      699\n",
       "keys                       0\n",
       "manufacturer             632\n",
       "manufacturerNumber       695\n",
       "name                       0\n",
       "prices                     0\n",
       "reviews.date             380\n",
       "reviews.doRecommend     1058\n",
       "reviews.numHelpful       697\n",
       "reviews.rating           420\n",
       "reviews.sourceURLs         0\n",
       "reviews.text               0\n",
       "reviews.title             17\n",
       "reviews.userCity        1597\n",
       "reviews.userProvince    1597\n",
       "reviews.username          17\n",
       "sizes                   1597\n",
       "upc                      699\n",
       "weight                   911\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "09004d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumit\\AppData\\Local\\Temp\\ipykernel_15704\\2652306643.py:14: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_reviews['reviews.doRecommend'] = df_reviews['reviews.doRecommend'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Select relevant columns\n",
    "review_cols = ['reviews.text', 'reviews.rating', 'reviews.title', 'reviews.doRecommend', 'reviews.numHelpful']\n",
    "df_reviews = df[review_cols].copy()\n",
    "\n",
    "# Drop rows with missing text\n",
    "df_reviews = df_reviews.dropna(subset=['reviews.text'])\n",
    "\n",
    "# Fill missing values\n",
    "df_reviews['reviews.title'] = df_reviews['reviews.title'].fillna(\"\")\n",
    "df_reviews['reviews.doRecommend'] = df_reviews['reviews.doRecommend'].fillna(False)\n",
    "df_reviews['reviews.numHelpful'] = df_reviews['reviews.numHelpful'].fillna(0)\n",
    "df_reviews['reviews.rating'] = df_reviews['reviews.rating'].fillna(df_reviews['reviews.rating'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5b1ae16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "asins                      0\n",
       "brand                      0\n",
       "categories                 0\n",
       "colors                   823\n",
       "dateAdded                  0\n",
       "dateUpdated                0\n",
       "dimension               1032\n",
       "ean                      699\n",
       "keys                       0\n",
       "manufacturer             632\n",
       "manufacturerNumber       695\n",
       "name                       0\n",
       "prices                     0\n",
       "reviews.date             380\n",
       "reviews.doRecommend     1058\n",
       "reviews.numHelpful       697\n",
       "reviews.rating           420\n",
       "reviews.sourceURLs         0\n",
       "reviews.text               0\n",
       "reviews.title             17\n",
       "reviews.userCity        1597\n",
       "reviews.userProvince    1597\n",
       "reviews.username          17\n",
       "sizes                   1597\n",
       "upc                      699\n",
       "weight                   911\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "51527a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1597, 27)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0332b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "adba3793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sumit\\AppData\\Local\\Temp\\ipykernel_15704\\881063938.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviews.doRecommend'].fillna(False, inplace=True)\n",
      "C:\\Users\\Sumit\\AppData\\Local\\Temp\\ipykernel_15704\\881063938.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['reviews.doRecommend'].fillna(False, inplace=True)\n",
      "C:\\Users\\Sumit\\AppData\\Local\\Temp\\ipykernel_15704\\881063938.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviews.numHelpful'].fillna(0, inplace=True)\n",
      "C:\\Users\\Sumit\\AppData\\Local\\Temp\\ipykernel_15704\\881063938.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviews.title'].fillna('', inplace=True)\n",
      "C:\\Users\\Sumit\\AppData\\Local\\Temp\\ipykernel_15704\\881063938.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviews.username'].fillna('Anonymous', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned and saved 1954 reviews.\n"
     ]
    }
   ],
   "source": [
    "irrelevant_cols = [\n",
    "    'id', 'asins', 'colors', 'dateAdded', 'dateUpdated', 'dimension', 'ean',\n",
    "    'keys', 'manufacturer', 'manufacturerNumber', 'upc', 'weight', 'sizes',\n",
    "    'reviews.userCity', 'reviews.userProvince', 'reviews.sourceURLs'\n",
    "]\n",
    "df.drop(columns=irrelevant_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# Step 3: Drop rows with missing critical fields (like text or rating)\n",
    "df.dropna(subset=['reviews.text', 'reviews.rating'], inplace=True)\n",
    "\n",
    "# Step 4: Fill remaining useful but sparse columns\n",
    "df['reviews.doRecommend'].fillna(False, inplace=True)\n",
    "df['reviews.numHelpful'].fillna(0, inplace=True)\n",
    "df['reviews.title'].fillna('', inplace=True)\n",
    "df['reviews.username'].fillna('Anonymous', inplace=True)\n",
    "\n",
    "# Step 5: Convert ratings to integer\n",
    "df['reviews.rating'] = df['reviews.rating'].astype(int)\n",
    "\n",
    "# Step 6: Optional - Bin ratings (e.g., 1-2: Negative, 3: Neutral, 4-5: Positive)\n",
    "def map_sentiment(r):\n",
    "    if r <= 2:\n",
    "        return \"negative\"\n",
    "    elif r == 3:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "df['sentiment'] = df['reviews.rating'].apply(map_sentiment)\n",
    "\n",
    "# Step 7: Handle class imbalance (e.g., balance positive/negative for fake review task)\n",
    "# For this example, let's keep only positive & negative, and upsample the minority class\n",
    "\n",
    "df_bal = df[df['sentiment'] != 'neutral']\n",
    "positive = df_bal[df_bal['sentiment'] == 'positive']\n",
    "negative = df_bal[df_bal['sentiment'] == 'negative']\n",
    "\n",
    "if len(positive) > len(negative):\n",
    "    negative_upsampled = resample(negative, replace=True, n_samples=len(positive), random_state=42)\n",
    "    df_balanced = pd.concat([positive, negative_upsampled])\n",
    "else:\n",
    "    positive_upsampled = resample(positive, replace=True, n_samples=len(negative), random_state=42)\n",
    "    df_balanced = pd.concat([negative, positive_upsampled])\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# ‚úÖ Save cleaned and balanced data\n",
    "df_balanced.to_csv(\"cleaned_balanced_reviews.csv\", index=False)\n",
    "print(f\"‚úÖ Cleaned and saved {len(df_balanced)} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1717bc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand                    0\n",
       "categories               0\n",
       "name                     0\n",
       "prices                   0\n",
       "reviews.date           217\n",
       "reviews.doRecommend      0\n",
       "reviews.numHelpful       0\n",
       "reviews.rating           0\n",
       "reviews.text             0\n",
       "reviews.title            0\n",
       "reviews.username         0\n",
       "sentiment                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb26fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ After dropping, 1689 reviews remain.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_balanced.dropna(subset=['reviews.date'], inplace=True)\n",
    "df_balanced.reset_index(drop=True, inplace=True)\n",
    "print(f\"‚úÖ After dropping, {len(df_balanced)} reviews remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23d9d37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1177, 12)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa6e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç Generating BERT Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1954/1954 [08:28<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved BERT embeddings to 'bert_embedded_reviews_cleaned.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"cleaned_balanced_reviews.csv\")  # Replace with your actual cleaned CSV path\n",
    "\n",
    "assert 'reviews.text' in df.columns, \"'reviews.text' column missing!\"\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        return cls_embedding.squeeze().numpy()\n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"üîç Generating BERT Embeddings\")\n",
    "df['bert_embedding'] = df['reviews.text'].progress_apply(get_bert_embedding)\n",
    "\n",
    "df.to_pickle(\"bert_embedded_reviews_cleaned.pkl\")\n",
    "print(\"‚úÖ Saved BERT embeddings to 'bert_embedded_reviews_cleaned.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "95edb5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total labeled reviews: 485\n",
      "label\n",
      "0    451\n",
      "1     34\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Copy to avoid modifying the original DataFrame\n",
    "df_labeled = df.copy()\n",
    "\n",
    "# Heuristic labeling function\n",
    "def heuristic_label(row):\n",
    "    # Highly suspicious if not recommended, low rating, and not helpful\n",
    "    if (row['reviews.doRecommend'] == False) and (row['reviews.rating'] <= 2) and (row['reviews.numHelpful'] == 0):\n",
    "        return 0  # Fake\n",
    "    # Trusted if recommended, good rating, and has helpful votes\n",
    "    elif (row['reviews.doRecommend'] == True) and (row['reviews.rating'] >= 4) and (row['reviews.numHelpful'] > 0):\n",
    "        return 1  # Genuine\n",
    "    else:\n",
    "        return -1  # Ambiguous / Unlabeled\n",
    "\n",
    "df_labeled['label'] = df_labeled.apply(heuristic_label, axis=1)\n",
    "\n",
    "# Keep only labeled examples (0 or 1)\n",
    "df_labeled = df_labeled[df_labeled['label'] != -1].reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Total labeled reviews: {len(df_labeled)}\")\n",
    "print(df_labeled['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ede55cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        90\n",
      "           1       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.99        97\n",
      "   macro avg       0.99      0.93      0.96        97\n",
      "weighted avg       0.99      0.99      0.99        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Features and labels\n",
    "X = np.vstack(df_labeled['bert_embedding'].values)\n",
    "y = df_labeled['label'].values\n",
    "\n",
    "# Split before balancing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"‚úÖ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0283669e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved as 'logistic_model_fake_review.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(clf, \"logistic_model_fake_review.pkl\")\n",
    "print(\"‚úÖ Model saved as 'logistic_model_fake_review.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b7886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(text, model, tokenizer, bert_model):\n",
    "    import torch\n",
    "    # Tokenize and embed\n",
    "    inputs = tokenizer(\n",
    "        text, return_tensors='pt', truncation=True,\n",
    "        padding='max_length', max_length=512\n",
    "    )\n",
    "    inputs = {k: v.to(bert_model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**inputs)\n",
    "        cls_embedding = output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(cls_embedding)\n",
    "    return \"üü¢ Genuine\" if prediction[0] == 0 else \"üî¥ Fake\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad9f5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ Genuine\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "# Load everything\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").eval()\n",
    "bert_model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "model = joblib.load(\"logistic_model_fake_review.pkl\")\n",
    "\n",
    "# Predict\n",
    "sample_review = \"This circuits were not good\"\n",
    "print(predict_review(sample_review, model, tokenizer, bert_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe766fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
